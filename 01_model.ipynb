{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import TensorBoard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "class StandardScaler3D(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Feature-wise scaling\n",
    "        reshape data temporarily to [samples * time-steps , features] for feature-colums\n",
    "        Code modified from https://stackoverflow.com/a/61617645\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X.reshape(X.shape[0], -1))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.scaler.transform(X.reshape(X.shape[0], -1)).reshape(X.shape)\n",
    "\n",
    "\n",
    "class MinMaxScaler3D(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Feature-wise scaling\n",
    "        reshape data temporarily to [samples * time-steps , features] for feature-colums\n",
    "        Code modified from https://stackoverflow.com/a/61617645\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.scaler = MinMaxScaler()\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.scaler.fit(X.reshape(X.shape[0], -1))\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.scaler.transform(X.reshape(X.shape[0], -1)).reshape(X.shape)\n",
    "\n",
    "\n",
    "def feature_matrix_to_vector(X):\n",
    "    \"\"\" Concatenate arrays along the second axis\"\"\"\n",
    "    return np.reshape(X, (\n",
    "        X.shape[0],\n",
    "        X.shape[2]*X.shape[1]\n",
    "    ), order=\"F\")\n",
    "\n",
    "\n",
    "# TODO\n",
    "# rewrite for train and test set scaling\n",
    "# for example, using model.fit(train_data)\n",
    "# and then apply model.scale_ and model.mean_ to test_data.\n",
    "\n",
    "# hint: actually, this is standard in sklearn\n",
    "# use this scaler and do a unit test with manually calculated data for train & test set\n",
    "\n",
    "# TODO: Visualize data (1 trial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape = (4000, 500, 3)\n",
      "target.shape = (4000,)\n",
      "groups.shape = (4000,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = np.load(Path(r\"data/data.npy\")).astype(np.float32)\n",
    "target = np.load(Path(r\"data/target.npy\")).astype(np.int64)\n",
    "groups = np.load(Path(r\"data/groups.npy\")).astype(np.int64)\n",
    "\n",
    "print(f\"{data.shape = }\\n{target.shape = }\\n{groups.shape = }\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Baseline model (MLP)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "writer = SummaryWriter()\n",
    "callbacks = []\n",
    "callbacks.append(TensorBoard(writer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, num_units=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dense0 = nn.Linear(data.shape[1]*data.shape[2], num_units)\n",
    "        self.nonlin = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense1 = nn.Linear(num_units, num_units)\n",
    "        self.output = nn.Linear(num_units, 2)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.nonlin(self.dense1(X))\n",
    "        X = self.softmax(self.output(X))\n",
    "        return X\n",
    "\n",
    "# Create MLP\n",
    "MLP = NeuralNetClassifier(\n",
    "    MultiLayerPerceptron,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM\n",
    "class LongShortTermMemory(nn.Module):\n",
    "    def __init__(self, num_units=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=data.shape[2],\n",
    "            hidden_size=num_units,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.output = nn.Linear(num_units, 2)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "            \n",
    "            X, _ = self.lstm(X)\n",
    "            X = self.softmax(self.output(X[:, -1, :]))\n",
    "            return X\n",
    "    \n",
    "# Create LSTM\n",
    "LSTM = NeuralNetClassifier(\n",
    "    LongShortTermMemory,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- check if softmax with default nll-criterion gives the same result as cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "MLP_pipe = make_pipeline(\n",
    "    StandardScaler3D(),\n",
    "    FunctionTransformer(feature_matrix_to_vector),\n",
    "    MLP)\n",
    "\n",
    "LSTM_pipe = make_pipeline(\n",
    "    MinMaxScaler3D(),\n",
    "    LSTM)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4016\u001b[0m       \u001b[32m0.8325\u001b[0m        \u001b[35m0.2927\u001b[0m  0.2009\n",
      "      2        \u001b[36m0.3461\u001b[0m       0.8187        0.2942  0.1457\n",
      "      3        \u001b[36m0.3370\u001b[0m       0.8237        0.2957  0.1489\n",
      "      4        \u001b[36m0.3341\u001b[0m       0.8200        0.3029  0.1494\n",
      "      5        \u001b[36m0.3315\u001b[0m       0.7963        0.3070  0.1489\n",
      "      6        \u001b[36m0.3262\u001b[0m       0.8063        0.3083  0.1642\n",
      "      7        \u001b[36m0.3168\u001b[0m       0.8150        0.3037  0.1491\n",
      "      8        \u001b[36m0.3163\u001b[0m       0.8237        0.2985  0.1319\n",
      "      9        0.3189       0.7937        0.3213  0.1490\n",
      "     10        \u001b[36m0.3110\u001b[0m       0.8213        0.3045  0.1297\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler3d&#x27;, StandardScaler3D()),\n",
       "                (&#x27;functiontransformer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function feature_matrix_to_vector at 0x0000024BE5B22710&gt;)),\n",
       "                (&#x27;neuralnetclassifier&#x27;,\n",
       "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=MultiLayerPerceptron(\n",
       "    (dense0): Linear(in_features=1500, out_features=100, bias=True)\n",
       "    (nonlin): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (output): Linear(in_features=100, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  ),\n",
       "))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler3d&#x27;, StandardScaler3D()),\n",
       "                (&#x27;functiontransformer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function feature_matrix_to_vector at 0x0000024BE5B22710&gt;)),\n",
       "                (&#x27;neuralnetclassifier&#x27;,\n",
       "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=MultiLayerPerceptron(\n",
       "    (dense0): Linear(in_features=1500, out_features=100, bias=True)\n",
       "    (nonlin): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (output): Linear(in_features=100, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  ),\n",
       "))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler3D</label><div class=\"sk-toggleable__content\"><pre>StandardScaler3D()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function feature_matrix_to_vector at 0x0000024BE5B22710&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=MultiLayerPerceptron(\n",
       "    (dense0): Linear(in_features=1500, out_features=100, bias=True)\n",
       "    (nonlin): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (output): Linear(in_features=100, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  ),\n",
       ")</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler3d', StandardScaler3D()),\n",
       "                ('functiontransformer',\n",
       "                 FunctionTransformer(func=<function feature_matrix_to_vector at 0x0000024BE5B22710>)),\n",
       "                ('neuralnetclassifier',\n",
       "                 <class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MultiLayerPerceptron(\n",
       "    (dense0): Linear(in_features=1500, out_features=100, bias=True)\n",
       "    (nonlin): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (output): Linear(in_features=100, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLP_pipe.fit(data, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_pipe.fit(data, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "test_data = np.load(Path(r\"data/test_data.npy\")).astype(np.float32)\n",
    "test_target = np.load(Path(r\"data/test_target.npy\")).astype(np.int64)\n",
    "\n",
    "print(f\"{test_data.shape = }\\n{test_target.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_score = MLP_pipe.score(test_data, test_target)\n",
    "print(f\"{MLP_score = }\")\n",
    "\n",
    "LSTM_score = LSTM_pipe.score(test_data, test_target)\n",
    "print(f\"{LSTM_score = }\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GroupKFold(n_splits=5)\n",
    "test_score = cross_val_score(\n",
    "    LSTM_pipe,\n",
    "    data, target,\n",
    "    groups=groups, \n",
    "    cv=cv,\n",
    "    n_jobs=5)\n",
    "print(f\"The average accuracy is \"\n",
    "      f\"{test_score.mean():.3f} ± \"\n",
    "      f\"{test_score.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "X = [0.1, 0.2, 2.2, 2.4, 2.3, 4.55, 5.8, 8.8, 9, 10]\n",
    "y = [\"a\", \"b\", \"b\", \"b\", \"c\", \"c\", \"c\", \"d\", \"d\", \"d\"]\n",
    "groups = [1, 1, 1, 2, 2, 2, 3, 3, 3, 3]\n",
    "gkf = GroupKFold(n_splits=3)\n",
    "for train, test in gkf.split(X, y, groups=groups):\n",
    "    print(\"%s %s\" % (train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GroupKFold()\n",
    "test_score = cross_val_score(\n",
    "    LSTM_pipe,\n",
    "    data, \n",
    "    target, \n",
    "    groups=groups,\n",
    "    cv=cv, \n",
    "    n_jobs=5)\n",
    "print(f\"The average accuracy is \"\n",
    "      f\"{test_score.mean():.3f} ± \"\n",
    "      f\"{test_score.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 30\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n",
    "\n",
    "# We will use a Support Vector Classifier with \"rbf\" kernel\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=outer_cv)\n",
    "    clf.fit(X_iris, y_iris)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)\n",
    "    nested_score = cross_val_score(clf, X=X_iris, y=y_iris, cv=outer_cv)\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "\n",
    "score_difference = non_nested_scores - nested_scores\n",
    "\n",
    "print(\n",
    "    \"Average difference of {:6f} with std. dev. of {:6f}.\".format(\n",
    "        score_difference.mean(), score_difference.std()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot scores on each trial for nested and non-nested CV\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "(non_nested_scores_line,) = plt.plot(non_nested_scores, color=\"r\")\n",
    "(nested_line,) = plt.plot(nested_scores, color=\"b\")\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "plt.legend(\n",
    "    [non_nested_scores_line, nested_line],\n",
    "    [\"Non-Nested CV\", \"Nested CV\"],\n",
    "    bbox_to_anchor=(0, 0.4, 0.5, 0),\n",
    ")\n",
    "plt.title(\n",
    "    \"Non-Nested and Nested Cross Validation on Iris Dataset\",\n",
    "    x=0.5,\n",
    "    y=1.1,\n",
    "    fontsize=\"15\",\n",
    ")\n",
    "\n",
    "# Plot bar chart of the difference.\n",
    "plt.subplot(212)\n",
    "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "plt.xlabel(\"Individual Trial #\")\n",
    "plt.legend(\n",
    "    [difference_plot],\n",
    "    [\"Non-Nested CV - Nested CV Score\"],\n",
    "    bbox_to_anchor=(0, 1, 0.8, 0),\n",
    ")\n",
    "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with grid search\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # deactivate skorch-internal train-valid split and verbose logging\n",
    "# net.set_params(train_split=False, verbose=0)\n",
    "# params = {\n",
    "#     'lr': [0.01, 0.02],\n",
    "#     'max_epochs': [10, 20],\n",
    "#     'module__num_units': [100, 1000],\n",
    "# }\n",
    "# gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=2)\n",
    "\n",
    "# gs.fit(data, target)\n",
    "# print(\"best score: {:.3f}, best params: {}\".format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "test_data = np.load(Path(r\"data/test_data.npy\"))\n",
    "test_target = np.load(Path(r\"data/test_target.npy\"))\n",
    "\n",
    "# Scale data\n",
    "test_data = StandardScaler3D().fit_transform(test_data)\n",
    "\n",
    "# Reshape X to 1-D for MLP\n",
    "test_data = np.reshape(test_data, (\n",
    "    test_data.shape[0],\n",
    "    test_data.shape[2]*test_data.shape[1]\n",
    "), order=\"F\")\n",
    "\n",
    "plt.plot(test_data[142]);\n",
    "print(f\"{test_data.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, GroupKFold\n",
    "\n",
    "model = MLPClassifier(\n",
    "    random_state=1, \n",
    "    max_iter=500, \n",
    "    early_stopping=True)\n",
    "\n",
    "cv = GroupKFold()\n",
    "test_score = cross_val_score(model, data, target, groups=groups, cv=cv,\n",
    "                             n_jobs=5)\n",
    "print(f\"The average accuracy is \"\n",
    "      f\"{test_score.mean():.3f} ± \"\n",
    "      f\"{test_score.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = pd.DataFrame(\n",
    "    [test_score],\n",
    "    index=[\"KFold with groups\"],\n",
    ").T\n",
    "\n",
    "all_scores.plot.hist(bins=10, edgecolor=\"black\", alpha=0.7)\n",
    "plt.xlabel(\"Accuracy score\")\n",
    "_ = plt.title(\"Distribution of the test scores\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for tranform_to_1d\n",
    "\n",
    "# Reshape X to 1-D for MLP\n",
    "data = np.reshape(data, (\n",
    "    data.shape[0],\n",
    "    data.shape[2]*data.shape[1]\n",
    "), order=\"F\")\n",
    "\n",
    "plt.plot(data[142]);\n",
    "print(f\"{data.shape = }\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b99f9135959a9658cb812fe0ba5c4f69cd3d89b5662a926a2ace19e3111ee69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
