{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work in progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "PROJECT_DIR = Path.cwd()\n",
    "if PROJECT_DIR.stem == 'notebooks':\n",
    "    PROJECT_DIR = PROJECT_DIR.parent\n",
    "    sys.path.insert(0, '..')\n",
    "    %load_ext autoreload\n",
    "    %autoreload 2 # for local development purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.__version__ = '1.13.1'\n",
      "torch.cuda.is_available() = False\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch.callbacks import TensorBoard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GroupKFold, cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    matthews_corrcoef, \n",
    "    confusion_matrix, \n",
    "    ConfusionMatrixDisplay\n",
    "    )\n",
    "\n",
    "print(f\"{torch.__version__ = }\")\n",
    "print(f\"{torch.cuda.is_available() = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.features.scalers_3d import StandardScaler3D, MinMaxScaler3D, RobustScaler3D\n",
    "\n",
    "# TODO: add group standardization? or just use robust scaler?\n",
    "# -> could be important for transfer learning\n",
    "# https://stackoverflow.com/questions/55601928/apply-multiple-standardscalers-to-individual-groups\n",
    "\n",
    "from src.features.reshape_features_to_2d import reshape_features_to_2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pytorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "# TODO: take a look into basic usage notebook from the skorch documentation\n",
    "# change the path to the tensorboard logs (runs folder)\n",
    "writer = SummaryWriter()\n",
    "callbacks = []\n",
    "callbacks.append(TensorBoard(writer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP with pytorch\n",
    "class MultiLayerPerceptron(nn.Module):\n",
    "    def __init__(self, num_units=100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dense0 = nn.Linear(data.shape[1]*data.shape[2], num_units)\n",
    "        self.nonlin = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.dense1 = nn.Linear(num_units, num_units)\n",
    "        self.output = nn.Linear(num_units, 2)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.nonlin(self.dense1(X))\n",
    "        X = self.softmax(self.output(X))\n",
    "        return X\n",
    "\n",
    "\n",
    "# Create MLP with skorch\n",
    "mlp = NeuralNetClassifier(\n",
    "    MultiLayerPerceptron,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LSTM with pytorch\n",
    "class LongShortTermMemory(nn.Module):\n",
    "    def __init__(self, num_units=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=data.shape[2],\n",
    "            hidden_size=num_units,\n",
    "            num_layers=1,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.output = nn.Linear(num_units, 2)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X, _ = self.lstm(X)\n",
    "        X = self.softmax(self.output(X[:, -1, :]))\n",
    "        return X\n",
    "\n",
    "\n",
    "# Create LSTM with skorch\n",
    "lstm = NeuralNetClassifier(\n",
    "    LongShortTermMemory,\n",
    "    max_epochs=10,\n",
    "    lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "- check if softmax with default nll-criterion gives the same result as cross-entropy loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data.shape = (4000, 500, 3)\n",
      "target.shape = (4000,)\n",
      "groups.shape = (4000,)\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = PROJECT_DIR / 'data'\n",
    "DUMMY_DIR = DATA_DIR / 'dummy'\n",
    "\n",
    "data = np.load(DUMMY_DIR / \"data.npy\").astype(np.float32)\n",
    "target = np.load(DUMMY_DIR / \"target.npy\").astype(np.int64)\n",
    "groups = np.load(DUMMY_DIR / \"groups.npy\").astype(np.int64)\n",
    "\n",
    "print(f\"{data.shape = }\\n{target.shape = }\\n{groups.shape = }\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipelines with sklearn\n",
    "mlp_pipe = make_pipeline(\n",
    "    StandardScaler3D(),\n",
    "    FunctionTransformer(reshape_features_to_2D), \n",
    "    mlp)\n",
    "\n",
    "lstm_pipe = make_pipeline(\n",
    "    MinMaxScaler3D(),\n",
    "    lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.4225\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.2892\u001b[0m  0.2846\n",
      "      2        \u001b[36m0.3639\u001b[0m       0.7875        0.3066  0.8328\n",
      "      3        \u001b[36m0.3525\u001b[0m       0.8350        \u001b[35m0.2855\u001b[0m  0.3814\n",
      "      4        \u001b[36m0.3486\u001b[0m       0.7950        0.2951  0.4150\n",
      "      5        \u001b[36m0.3480\u001b[0m       0.7887        0.2960  0.2967\n",
      "      6        \u001b[36m0.3448\u001b[0m       0.8213        0.2895  0.5782\n",
      "      7        0.3471       0.8213        0.2879  0.2992\n",
      "      8        0.3465       0.8325        \u001b[35m0.2854\u001b[0m  0.2807\n",
      "      9        0.3453       0.8337        \u001b[35m0.2849\u001b[0m  0.3647\n",
      "     10        \u001b[36m0.3444\u001b[0m       0.8200        \u001b[35m0.2839\u001b[0m  0.2463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler3d&#x27;, StandardScaler3D()),\n",
       "                (&#x27;functiontransformer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function reshape_features_to_2D at 0x000002CCFC85CCA0&gt;)),\n",
       "                (&#x27;neuralnetclassifier&#x27;,\n",
       "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=MultiLayerPerceptron(\n",
       "    (dense0): Linear(in_features=1500, out_features=100, bias=True)\n",
       "    (nonlin): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (output): Linear(in_features=100, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  ),\n",
       "))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler3d&#x27;, StandardScaler3D()),\n",
       "                (&#x27;functiontransformer&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function reshape_features_to_2D at 0x000002CCFC85CCA0&gt;)),\n",
       "                (&#x27;neuralnetclassifier&#x27;,\n",
       "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=MultiLayerPerceptron(\n",
       "    (dense0): Linear(in_features=1500, out_features=100, bias=True)\n",
       "    (nonlin): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (output): Linear(in_features=100, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  ),\n",
       "))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler3D</label><div class=\"sk-toggleable__content\"><pre>StandardScaler3D()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function reshape_features_to_2D at 0x000002CCFC85CCA0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=MultiLayerPerceptron(\n",
       "    (dense0): Linear(in_features=1500, out_features=100, bias=True)\n",
       "    (nonlin): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (output): Linear(in_features=100, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  ),\n",
       ")</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler3d', StandardScaler3D()),\n",
       "                ('functiontransformer',\n",
       "                 FunctionTransformer(func=<function reshape_features_to_2D at 0x000002CCFC85CCA0>)),\n",
       "                ('neuralnetclassifier',\n",
       "                 <class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MultiLayerPerceptron(\n",
       "    (dense0): Linear(in_features=1500, out_features=100, bias=True)\n",
       "    (nonlin): ReLU()\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (output): Linear(in_features=100, out_features=2, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_pipe.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_pipe.fit(data, target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_test = np.load(DUMMY_DIR / \"data_test.npy\").astype(np.float32)\n",
    "target_test = np.load(DUMMY_DIR / \"target_test.npy\").astype(np.float32)\n",
    "\n",
    "print(f\"{data_test.shape = }\\n{target_test.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for MLP classifier\n",
    "\n",
    "target_predicted = mlp_pipe.predict(data_test)\n",
    "\n",
    "cm = confusion_matrix(target_test, target_predicted)\n",
    "acc = accuracy_score(target_test, target_predicted)\n",
    "mcc = matthews_corrcoef(target_test, target_predicted)\n",
    "\n",
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix=cm, \n",
    "    display_labels=mlp_pipe.classes_,\n",
    "    ).plot()\n",
    "\n",
    "print(\"Metrics for MLP classifier:\")\n",
    "print(f\"{acc = }\\n{mcc = }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_score = mlp_pipe.score(data_test, target_test)\n",
    "print(f\"{mlp_score = }\")\n",
    "\n",
    "lstm_score = lstm_pipe.score(data_test, target_test)\n",
    "print(f\"{lstm_score = }\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroupKFold cross-validation \n",
    "(doing it right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GroupKFold(n_splits=5)\n",
    "test_score = cross_val_score(\n",
    "    mlp_pipe,\n",
    "    data, target,\n",
    "    groups=groups,\n",
    "    cv=cv,\n",
    "    n_jobs=5)\n",
    "print(f\"The average accuracy is \"\n",
    "      f\"{test_score.mean():.3f} ± \"\n",
    "      f\"{test_score.std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = GroupKFold()\n",
    "test_score = cross_val_score(\n",
    "    lstm_pipe,\n",
    "    data, \n",
    "    target, \n",
    "    groups=groups,\n",
    "    cv=cv, \n",
    "    n_jobs=5)\n",
    "print(f\"The average accuracy is \"\n",
    "      f\"{test_score.mean():.3f} ± \"\n",
    "      f\"{test_score.std():.3f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search\n",
    "use randomizedgridsearch: https://scikit-learn.org/stable/modules/grid_search.html#grid-search"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More stuff (WIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
    "import numpy as np\n",
    "\n",
    "# Number of random trials\n",
    "NUM_TRIALS = 30\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X_iris = iris.data\n",
    "y_iris = iris.target\n",
    "\n",
    "# Set up possible values of parameters to optimize over\n",
    "p_grid = {\"C\": [1, 10, 100], \"gamma\": [0.01, 0.1]}\n",
    "\n",
    "# We will use a Support Vector Classifier with \"rbf\" kernel\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "\n",
    "# Arrays to store scores\n",
    "non_nested_scores = np.zeros(NUM_TRIALS)\n",
    "nested_scores = np.zeros(NUM_TRIALS)\n",
    "\n",
    "# Loop for each trial\n",
    "for i in range(NUM_TRIALS):\n",
    "\n",
    "    # Choose cross-validation techniques for the inner and outer loops,\n",
    "    # independently of the dataset.\n",
    "    # E.g \"GroupKFold\", \"LeaveOneOut\", \"LeaveOneGroupOut\", etc.\n",
    "    inner_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "    outer_cv = KFold(n_splits=4, shuffle=True, random_state=i)\n",
    "\n",
    "    # Non_nested parameter search and scoring\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=outer_cv)\n",
    "    clf.fit(X_iris, y_iris)\n",
    "    non_nested_scores[i] = clf.best_score_\n",
    "\n",
    "    # Nested CV with parameter optimization\n",
    "    clf = GridSearchCV(estimator=svm, param_grid=p_grid, cv=inner_cv)\n",
    "    nested_score = cross_val_score(clf, X=X_iris, y=y_iris, cv=outer_cv)\n",
    "    nested_scores[i] = nested_score.mean()\n",
    "\n",
    "score_difference = non_nested_scores - nested_scores\n",
    "\n",
    "print(\n",
    "    \"Average difference of {:6f} with std. dev. of {:6f}.\".format(\n",
    "        score_difference.mean(), score_difference.std()\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot scores on each trial for nested and non-nested CV\n",
    "plt.figure()\n",
    "plt.subplot(211)\n",
    "(non_nested_scores_line,) = plt.plot(non_nested_scores, color=\"r\")\n",
    "(nested_line,) = plt.plot(nested_scores, color=\"b\")\n",
    "plt.ylabel(\"score\", fontsize=\"14\")\n",
    "plt.legend(\n",
    "    [non_nested_scores_line, nested_line],\n",
    "    [\"Non-Nested CV\", \"Nested CV\"],\n",
    "    bbox_to_anchor=(0, 0.4, 0.5, 0),\n",
    ")\n",
    "plt.title(\n",
    "    \"Non-Nested and Nested Cross Validation on Iris Dataset\",\n",
    "    x=0.5,\n",
    "    y=1.1,\n",
    "    fontsize=\"15\",\n",
    ")\n",
    "\n",
    "# Plot bar chart of the difference.\n",
    "plt.subplot(212)\n",
    "difference_plot = plt.bar(range(NUM_TRIALS), score_difference)\n",
    "plt.xlabel(\"Individual Trial #\")\n",
    "plt.legend(\n",
    "    [difference_plot],\n",
    "    [\"Non-Nested CV - Nested CV Score\"],\n",
    "    bbox_to_anchor=(0, 1, 0.8, 0),\n",
    ")\n",
    "plt.ylabel(\"score difference\", fontsize=\"14\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # with grid search\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # deactivate skorch-internal train-valid split and verbose logging\n",
    "# net.set_params(train_split=False, verbose=0)\n",
    "# params = {\n",
    "#     'lr': [0.01, 0.02],\n",
    "#     'max_epochs': [10, 20],\n",
    "#     'module__num_units': [100, 1000],\n",
    "# }\n",
    "# gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=2)\n",
    "\n",
    "# gs.fit(data, target)\n",
    "# print(\"best score: {:.3f}, best params: {}\".format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_test = np.load(Path(r\"data/data_test.npy\"))\n",
    "target_test = np.load(Path(r\"data/target_test.npy\"))\n",
    "\n",
    "# Scale data\n",
    "data_test = StandardScaler3D().fit_transform(data_test)\n",
    "\n",
    "# Reshape X to 1-D for MLP\n",
    "data_test = np.reshape(data_test, (\n",
    "    data_test.shape[0],\n",
    "    data_test.shape[2]*data_test.shape[1]\n",
    "), order=\"F\")\n",
    "\n",
    "plt.plot(data_test[142]);\n",
    "print(f\"{data_test.shape = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score, GroupKFold\n",
    "\n",
    "model = MLPClassifier(\n",
    "    random_state=1, \n",
    "    max_iter=500, \n",
    "    early_stopping=True)\n",
    "\n",
    "cv = GroupKFold()\n",
    "test_score = cross_val_score(model, data, target, groups=groups, cv=cv,\n",
    "                             n_jobs=5)\n",
    "print(f\"The average accuracy is \"\n",
    "      f\"{test_score.mean():.3f} ± \"\n",
    "      f\"{test_score.std():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = pd.DataFrame(\n",
    "    [test_score],\n",
    "    index=[\"KFold with groups\"],\n",
    ").T\n",
    "\n",
    "all_scores.plot.hist(bins=10, edgecolor=\"black\", alpha=0.7)\n",
    "plt.xlabel(\"Accuracy score\")\n",
    "_ = plt.title(\"Distribution of the test scores\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compare 3d standardization with old version, which was done by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for tranform_to_1d\n",
    "\n",
    "# Reshape X to 1-D for MLP\n",
    "data = np.reshape(data, (\n",
    "    data.shape[0],\n",
    "    data.shape[2]*data.shape[1]\n",
    "), order=\"F\")\n",
    "\n",
    "plt.plot(data[142]);\n",
    "print(f\"{data.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "X = range(100)\n",
    "y = target[:100]\n",
    "groups_ = groups[:1000:10]\n",
    "gkf = GroupKFold(n_splits=6)\n",
    "for train, test in gkf.split(X, y, groups=groups_):\n",
    "    print(\"%s %s\" % (train, test))\n",
    "    print(f\"{train.shape = }\\n{test.shape = }\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b99f9135959a9658cb812fe0ba5c4f69cd3d89b5662a926a2ace19e3111ee69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
